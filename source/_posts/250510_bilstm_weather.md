---
title: åŸºäºåŒå‘é•¿çŸ­æœŸè®°å¿†ç¥ç»ç½‘ç»œå’Œä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œé¢„æµ‹æœªæ¥æ°”è±¡ç»“æœ
date: 2025-05-10 19:39:13
tags: [Python, æœºå™¨å­¦ä¹ , æ—¶é—´åºåˆ—]
categories: [[æ¡ˆä¾‹åˆ†äº«, æœºå™¨å­¦ä¹ ]]
---


<p>
åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œåºåˆ—æ•°æ®çš„å¤„ç†ä¸€ç›´æ˜¯ä¸€ä¸ªå…³é”®ä»»åŠ¡ã€‚æ—¶é—´åºåˆ—æ¨¡å‹æ˜¯æ ¹æ®ç³»ç»Ÿè§‚æµ‹å¾—åˆ°çš„æ—¶é—´åºåˆ—æ•°æ®ï¼Œé€šè¿‡æ›²çº¿æ‹Ÿåˆå’Œå‚æ•°ä¼°è®¡æ¥å»ºç«‹æ•°å­¦æ¨¡å‹çš„ç†è®ºå’Œæ–¹æ³•ã€‚
</p>
<p>
åœ¨å¾ˆå¤šçš„æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œåˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰çš„æ··åˆæ¨¡å‹æ˜¯ç›®å‰å¸¸è§çš„æ·±åº¦å­¦ä¹ è§£å†³æ–¹æ¡ˆä¹‹ä¸€ã€‚CNN
å’Œ LSTM å„è‡ªæœ‰ä¸åŒçš„ç‰¹é•¿ï¼ŒCNN æ“…é•¿å±€éƒ¨æ¨¡å¼çš„æ•æ‰ï¼ŒLSTM
æ“…é•¿æ•æ‰åºåˆ—çš„é•¿ä¾èµ–å…³ç³»ã€‚é€šè¿‡æ··åˆè¿™ä¸¤ç§ç½‘ç»œï¼Œå¯ä»¥éå¸¸å¥½åœ°å­¦ä¹ æ—¶é—´åºåˆ—æ•°æ®ä¸­çš„å¤æ‚æ¨¡å¼ã€‚
</p>

# è®¾ç½®è¿è¡Œç¯å¢ƒ

``` r
# æŒ‡å®š Python ç¯å¢ƒ
reticulate::use_python("C:/ProgramData/Anaconda3/python.exe")

# åˆ‡æ¢å·¥ä½œç›®å½•
wkdir = dirname(rstudioapi::getActiveDocumentContext()$path)
```

# å¯¼å…¥æ‰€éœ€åº“

``` python
import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.metrics import r2_score
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Bidirectional, Dense
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Reshape, Flatten
```

# è‡ªå®šä¹‰å‡½æ•°

``` python
# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå¯¹è¾“å…¥çš„è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œæ•°æ®å½’ä¸€åŒ–å¤„ç†
def normalize_dataframe(train_set, val_set, test_set):
    # åˆå§‹åŒ–`MinMaxScaler`å¯¹è±¡ï¼Œç”¨äºå°†æ•°æ®å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
    scaler = MinMaxScaler()
    # åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆå½’ä¸€åŒ–æ¨¡å‹ï¼Œè®¡ç®—æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
    # è¿™ä¸€æ­¥ä¸ä¼šå¯¹è®­ç»ƒé›†ï¼Œä»…è®°å½•å½’ä¸€åŒ–å‚æ•°
    scaler.fit(train_set)
    # ä½¿ç”¨è®­ç»ƒé›†æ‹Ÿåˆçš„å½’ä¸€åŒ–æ¨¡å‹å¯¹è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œè½¬æ¢
    # è½¬æ¢åçš„æ•°æ®ä¿æŒåŸæœ‰çš„åˆ—åå’Œç´¢
    train = pd.DataFrame(scaler.transform(train_set), columns = train_set.columns, index = train_set.index)
    val = pd.DataFrame(scaler.transform(val_set), columns = val_set.columns, index = val_set.index)
    test = pd.DataFrame(scaler.transform(test_set), columns = test_set.columns, index = test_set.index)
    
    # è¿”å›å½’ä¸€åŒ–åçš„è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†
    return train, val, test

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œå°†å…¶è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹è¾“å…¥çš„æ ¼å¼
def prepare_data(data, win_size):
    X = []  # å­˜å‚¨è¾“å…¥ç‰¹å¾ï¼ˆæ—¶é—´çª—å£å†…çš„æ•°æ®ï¼‰
    y = []  # å­˜å‚¨ç›®æ ‡å€¼ï¼ˆæ—¶é—´çª—å£åçš„æ•°æ®ï¼‰

    # éå†æ•°æ®ï¼Œåˆ›å»ºæ—¶é—´çª—å£å¤§å°ä¸º win_size çš„è¾“å…¥å’Œå¯¹åº”çš„ç›®æ ‡å€¼
    for i in range(len(data) - win_size):
        # æå–ä¸€ä¸ªæ—¶é—´çª—å£çš„æ•°æ®ä½œä¸ºè¾“å…¥
        temp_x = data[i:i + win_size]
        # æå–æ—¶é—´çª—å£åçš„æ•°æ®ä½œä¸ºç›®æ ‡å€¼
        temp_y = data[i + win_size]    
        X.append(temp_x)
        y.append(temp_y)
        
    # å°†åˆ—è¡¨è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œä¾¿äºåç»­æ¨¡å‹è¾“å…¥
    X = np.asarray(X)
    y = np.asarray(y)
    X = np.expand_dims(X, axis = -1)
    
    # è¿”å›è¾“å…¥ç‰¹å¾å’Œç›®æ ‡å€¼
    return X, y
```

# å…¨å±€ç¯å¢ƒå˜é‡

``` python
# å…¨å±€ç¯å¢ƒå˜é‡
win_size = 30                 # å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œè®¾ç½®æ—¶é—´çª—å£å¤§å°ä¸º 30
epoch_size = 100              # è®¾ç½® epoch æ¬¡æ•°ä¸º 100ï¼ˆè¿™é‡Œæµ‹è¯•è®¾ç½®å€¼è¾ƒå°ï¼Œå…·ä½“æ ¹æ®å®é™…è®¾ç½®ï¼‰
batch_size = 32               # è®¾ç½®æ‰¹é‡å¤§å°
verbose = 0                   # æ˜¯å¦æ‰“å°ä¸­é—´è¿‡ç¨‹ï¼Œ0 è¡¨ç¤ºé™é»˜çŠ¶æ€
train_ratio = 0.7             # è®­ç»ƒé›†æ¯”ä¾‹
val_ratio = 0.1               # éªŒè¯é›†æ¯”ä¾‹
test_ratio = 0.2              # æµ‹è¯•é›†æ¯”ä¾‹
```

# è®¾ç½®éšæœºç§å­

``` python
# è®¾ç½®éšæœºç§å­
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)   

# å¢å¼º TensorFlow çš„ç¡®å®šæ€§
os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['TF_CUDNN_DETERMINISTIC'] = '1'
```

# åŠ è½½æ•°æ®

``` python
# åŠ è½½æ•°æ®
df = pd.read_csv('data/weather.csv')
df['Date'] = pd.to_datetime(df['Year'].astype(str) + '-' + df['Day'].astype(str), format = '%Y-%j')
df.set_index('Date', inplace = True)
df.drop(['Year', 'Day'], axis = 1, inplace = True)
col = 'Temperature'
df = df[[col]]

# ç”Ÿæˆæ—¶é—´èŒƒå›´
start_date = pd.Timestamp('1990-01-01')
end_date = pd.Timestamp('2023-03-01')
date_range = pd.date_range(start = start_date, end = end_date, freq = 'D')

# æ£€æŸ¥æ—¶é—´èŒƒå›´ä¸­æ˜¯å¦åŒ…å« DataFrame ä¸­çš„æ‰€æœ‰æ—¥æœŸ
missing_dates = date_range[~date_range.isin(df.index)]
print("Missing Dates:")
```

    ## Missing Dates:

``` python
print(missing_dates)
```

    ## DatetimeIndex([], dtype='datetime64[ns]', freq='D')

# å¯è§†åŒ–æ•°æ®é›†

``` python
plt.figure(figsize = (15, 5))
plt.plot(df[col], color = '#00A087',  alpha = 0.3)
plt.title('')
plt.xticks(rotation = 0)
## (array([ 6574.,  8035.,  9496., 10957., 12418., 13879., 15340., 16801.,
##        18262., 19723.]), [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
plt.show()
```

![](/imgs/153c1049c2906567944c66d807a6a1d6.png)
# æ•°æ®å¤„ç†

## æ•°æ®é›†åˆ’åˆ†

``` python
# è®¡ç®—åˆ’åˆ†çš„ç´¢å¼•
train_split = int(train_ratio * len(df))
val_split = int((train_ratio + val_ratio) * len(df))

# åˆ’åˆ†æ•°æ®é›†
train_set = df.iloc[:train_split]
val_set = df.iloc[train_split:val_split]
test_set = df.iloc[val_split:]
```

## å¯è§†åŒ–è®­ç»ƒé›†, éªŒè¯é›†å’Œæµ‹è¯•é›†æ•°æ®

``` python
plt.figure(figsize = (15, 10))
plt.subplot(3, 1, 1)
plt.plot(train_set, color = 'g',  alpha = 0.3)
plt.title('Training Data')

plt.subplot(3, 1, 2)
plt.plot(val_set, color = 'b',  alpha = 0.3)
plt.title('Validation Data')

plt.subplot(3, 1, 3)
plt.plot(test_set, color = 'r',  alpha = 0.3)
plt.title('Testing Data')
plt.xticks(rotation = 0)
## (array([16801., 17167., 17532., 17897., 18262., 18628., 18993., 19358.]), [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
plt.show()
```

![](/imgs/5c70c3ff8121b74da43a44c9df8a0532.png)
## å½’ä¸€åŒ–å¤„ç†

``` python
# å¯¹è®­ç»ƒé›†, éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
train, val, test = normalize_dataframe(train_set, val_set, test_set)
```

## å¯è§†åŒ–å½’ä¸€åŒ–åçš„è®­ç»ƒé›†, éªŒè¯é›†å’Œæµ‹è¯•é›†æ•°æ®

``` python
plt.figure(figsize = (15, 10))
plt.subplot(3, 1, 1)
plt.plot(train, color = 'g',  alpha = 0.3)
plt.title('Training Data')

plt.subplot(3, 1, 2)
plt.plot(val, color = 'b',  alpha = 0.3)
plt.title('Validation Data')

plt.subplot(3, 1, 3)
plt.plot(test, color = 'r',  alpha = 0.3)
plt.title('Testing Data')
plt.xticks(rotation = 0)
## (array([16801., 17167., 17532., 17897., 18262., 18628., 18993., 19358.]), [Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, ''), Text(0, 0, '')])
plt.show()
```

![](/imgs/c85bb50f0c3a2f1e1c10f64d62e36f3c.png)
## å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®

``` python
# è®­ç»ƒé›†
X_train, y_train = prepare_data(train['Temperature'].values, win_size)

# éªŒè¯é›†
X_val, y_val= prepare_data(val['Temperature'].values, win_size)

# æµ‹è¯•é›†
X_test, y_test = prepare_data(test['Temperature'].values, win_size)

df_max = list(np.max(train_set))[0]
df_min = list(np.min(train_set))[0]

print("è®­ç»ƒé›†å½¢çŠ¶:", X_train.shape, y_train.shape)
## è®­ç»ƒé›†å½¢çŠ¶: (8449, 30, 1) (8449,)
print("éªŒè¯é›†å½¢çŠ¶:", X_val.shape, y_val.shape)
## éªŒè¯é›†å½¢çŠ¶: (1181, 30, 1) (1181,)
print("æµ‹è¯•é›†å½¢çŠ¶:", X_test.shape, y_test.shape)
## æµ‹è¯•é›†å½¢çŠ¶: (2393, 30, 1) (2393,)
```

# æ„å»ºé¢„æµ‹æ¨¡å‹

## åŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œ

<p>
åŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œ (Bi-LSTM)ï¼Œæ˜¯ä¸€ç§ç‰¹æ®Šçš„ LSTM
ç»“æ„ï¼Œå®ƒåŒæ—¶å¤„ç†åºåˆ—çš„æ­£å‘å’Œæ–¹å‘ä¿¡æ¯ã€‚è¿™æ„å‘³ç€å¯¹äºç»™å®šçš„æ—¶é—´æ­¥ï¼ŒåŒå‘
LSTM ä¸ä»…è€ƒè™‘äº†ä¹‹å‰çš„æ—¶é—´æ­¥ä¿¡æ¯ï¼Œåƒæ ‡å‡†çš„å•å‘ LSTM
ä¸€æ ·ï¼Œè¿˜è€ƒè™‘äº†æœªæ¥æ—¶é—´æ­¥çš„ä¿¡æ¯ã€‚è¿™ä½¿å¾— Bi-LSTM
åœ¨å¤„ç†è‡ªç„¶è¯­è¨€ä»»åŠ¡ã€è¯­éŸ³è¯†åˆ«å’Œå…¶ä»–éœ€è¦ç†è§£ä¸Šä¸‹æ–‡çš„ä»»åŠ¡æ—¶éå¸¸æœ‰ç”¨ã€‚
</p>
<p>
`Bi-LSTM`ç‰¹åˆ«é€‚åˆæ—¶é—´åºåˆ—æ•°æ®ï¼Œå› ä¸ºå®ƒå¯ä»¥åŒæ—¶è€ƒè™‘è¿‡å»å’Œæœªæ¥çš„ä¾èµ–å…³ç³»ï¼›å¯¹äºæ¸©åº¦é¢„æµ‹ä»»åŠ¡ï¼Œè¿™ç§æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰æ•°æ®ä¸­çš„é•¿æœŸä¾èµ–å’Œè¶‹åŠ¿ã€‚ç›¸æ¯”å•å‘ï¼ŒåŒå‘é€šè¿‡æ­£å‘å’Œæ–¹å‘å¤„ç†åºåˆ—ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£æ•°æ®çš„ä¸Šä¸‹æ–‡ï¼Œå°¤å…¶æ˜¯åœ¨åºåˆ—æ•°æ®ä¸­å­˜åœ¨å‰åä¾èµ–å…³ç³»ã€‚
</p>
<p>
è¿™ä¸ªä»£ç ä½¿ç”¨çš„æ¨¡å‹æ˜¯åŸºäº`Bi-LSTM`çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ã€‚æ¨¡å‹é€šè¿‡`Bi-LSTM`å±‚æå–æ—¶é—´åºåˆ—ç‰¹å¾ï¼Œå¹¶é€šè¿‡å¤šä¸ªå…¨è¿æ¥å±‚è¿›è¡Œå›å½’é¢„æµ‹ï¼Œæœ€ç»ˆè¾“å‡ºå•ä¸€çš„é¢„æµ‹å€¼ï¼ˆå¦‚æ¸©åº¦ï¼‰ã€‚
</p>

### æ„å»º Bi-LSTM æ¨¡å‹

<p>

æ„å»º Bi-LSTM æ¨¡å‹ï¼ŒåŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œ&lt;/&gt;

``` python
# åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
model = Sequential()
# æ·»åŠ åŒå‘ LSTM å±‚ï¼Œ128 ä¸ªå•å…ƒï¼Œæ¿€æ´»å‡½æ•°ä¸º reluï¼Œè¾“å…¥å½¢çŠ¶ä¸º (æ—¶é—´çª—å£å¤§å°, ç‰¹å¾æ•°é‡)
model.add(Bidirectional(LSTM(128, activation = 'relu'), input_shape = (X_train.shape[1], X_train.shape[2])))
# æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ64 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
model.add(Dense(64, activation = 'relu'))
# æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
model.add(Dense(32, activation = 'relu'))
# æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
model.add(Dense(16, activation = 'relu'))
# è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
model.add(Dense(1, activation = 'sigmoid'))
```

### ç¼–è¯‘æ¨¡å‹

``` python
# ç¼–è¯‘æ¨¡å‹ï¼Œä¼˜åŒ–å™¨ä¸º adamï¼ŒæŸå¤±å‡½æ•°ä¸ºå‡æ–¹è¯¯å·® (mse)
model.compile(optimizer = 'adam', loss = 'mse')
```

### è®­ç»ƒæ¨¡å‹

``` python
# è®­ç»ƒæ¨¡å‹ï¼Œè®¾ç½® epoch æ¬¡æ•°ä¸º 10ï¼ˆè¿™é‡Œæµ‹è¯•è®¾ç½®å€¼è¾ƒå°ï¼Œå…·ä½“æ ¹æ®å®é™…è®¾ç½®ï¼‰ï¼Œæ‰¹é‡å¤§å°ä¸º 32ï¼Œä½¿ç”¨éªŒè¯é›†è¯„ä¼°æ¨¡å‹
history = model.fit(X_train, y_train, epochs = epoch_size, batch_size = batch_size, validation_data = (X_val, y_val), verbose = verbose)
```

### ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±æ›²çº¿

``` python
plt.figure()
plt.plot(history.history['loss'], c = 'b', label = 'loss')
plt.plot(history.history['val_loss'], c = 'g', label = 'val_loss')
plt.legend()
plt.show()
```

![](/imgs/e1b875bbe5fbf4a3243ae05f8efa8ce1.png)
### ä½¿ç”¨æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹

``` python
y_pred = model.predict(X_test)
```

    ## 
    ## [1m 1/75[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m9s[0m 126ms/step
    ## [1m20/75[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step  
    ## [1m38/75[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step
    ## [1m54/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 3ms/step
    ## [1m73/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 3ms/step
    ## [1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step
    ## [1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step

### è®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

``` python
# è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
mse = metrics.mean_squared_error(y_test, np.array([i for arr in y_pred for i in arr]))
# è®¡ç®—å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
rmse = np.sqrt(mse)
# è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
mae = metrics.mean_absolute_error(y_test, np.array([i for arr in y_pred for i in arr]))
# è®¡ç®— RÂ² æ‹Ÿåˆä¼˜åº¦
r2 = r2_score(y_test, np.array([i for arr in y_pred for i in arr]))

print("å‡æ–¹è¯¯å·® (MSE):", mse)
## å‡æ–¹è¯¯å·® (MSE): 0.0009024836310498792
print("å‡æ–¹æ ¹è¯¯å·® (RMSE):", rmse)
## å‡æ–¹æ ¹è¯¯å·® (RMSE): 0.03004136533265223
print("å¹³å‡ç»å¯¹è¯¯å·® (MAE):", mae)
## å¹³å‡ç»å¯¹è¯¯å·® (MAE): 0.023367103850682486
print("æ‹Ÿåˆä¼˜åº¦:", r2)
## æ‹Ÿåˆä¼˜åº¦: 0.9709102190822203
```

### æ‰“å°æ¨¡å‹ç»“æ„æ‘˜è¦

``` python
model.summary()
## Model: "sequential"
## â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
## â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ bidirectional (Bidirectional)   â”‚ (None, 256)            â”‚       133,120 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense (Dense)                   â”‚ (None, 64)             â”‚        16,448 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_1 (Dense)                 â”‚ (None, 32)             â”‚         2,080 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_2 (Dense)                 â”‚ (None, 16)             â”‚           528 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_3 (Dense)                 â”‚ (None, 1)              â”‚            17 â”‚
## â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
##  Total params: 456,581 (1.74 MB)
##  Trainable params: 152,193 (594.50 KB)
##  Non-trainable params: 0 (0.00 B)
##  Optimizer params: 304,388 (1.16 MB)
```

### æœªæ¥è¾“å‡ºé¢„æµ‹

``` python
# å–å‡ºé¢„æµ‹çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥
last_output = model.predict(X_test, verbose = verbose)[-1]

# é¢„æµ‹çš„æ—¶é—´æ­¥æ•°
steps = 10  # å‡è®¾å‘åé¢„æµ‹ 10 ä¸ªæ—¶é—´æ­¥
predicted = []
for i in range(steps):
    # å°†æœ€åä¸€ä¸ªè¾“å‡ºåŠ å…¥ X_testï¼Œç»§ç»­å‘åé¢„æµ‹
    input_data = np.append(X_test[-1][1:], last_output).reshape(1, X_test.shape[1], X_test.shape[2])
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    next_output = model.predict(input_data, verbose = verbose)
    # å°†é¢„æµ‹çš„å€¼åŠ å…¥ç»“æœåˆ—è¡¨
    predicted.append(next_output[0][0])
    last_output = next_output[0]

print("å‘åé¢„æµ‹çš„å€¼:", predicted)
## å‘åé¢„æµ‹çš„å€¼: [0.5347221, 0.54252774, 0.5505376, 0.55875146, 0.56716347, 0.5757619, 0.58452773, 0.5930122, 0.60100317, 0.6083987]
```

``` python
series_1 = y_pred*(df_max - df_min) + df_min
series_2 = np.array(predicted)*(df_max - df_min) + df_min

plt.figure(figsize = (15,4), dpi = 300)

plt.subplot(3 ,1, 1)
plt.plot(train_set, color = 'c', label = 'Training Data')
plt.plot(val_set, color = 'r', label = 'Validation Data')
plt.plot(test_set, color = 'b', label = 'Testing Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.legend()

plt.subplot(3, 1, 2)
plt.plot(test_set, color = 'b', label = 'Training Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.legend()

plt.subplot(3, 1, 3)
plt.plot(test_set, color = 'b', label = 'Training Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.xlim(pd.Timestamp('2022-01-01'), pd.Timestamp('2023-03-11'))
## (18993.0, 19427.0)
plt.legend()

plt.show()
```

![](/imgs/24e7db63bcff89771fe5d4439f302279.png)
## æ··åˆç¥ç»ç½‘ç»œæ¨¡å‹

<p>
æ··åˆç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç»“åˆåŒå‘é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆBidirectional LSTM,
Bi-LSTMï¼‰å’Œä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆ1D
CNNï¼‰ï¼Œç”¨äºå¤„ç†æ—¶é—´åºåˆ—æˆ–åºåˆ—æ•°æ®çš„ä»»åŠ¡ï¼ˆå¦‚äºŒåˆ†ç±»é—®é¢˜ï¼‰ã€‚Bi-LSTM
æ“…é•¿æ•æ‰åºåˆ—ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè€Œ 1D CNN
æ“…é•¿æå–å±€éƒ¨ç‰¹å¾ã€‚é€šè¿‡ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ï¼Œæ¨¡å‹å¯ä»¥åœ¨å…¨å±€å’Œå±€éƒ¨ç‰¹å¾æå–ä¸Šéƒ½è¡¨ç°ä¼˜å¼‚ã€‚
</p>
<p>
ä¸€ä¸ª`Bi-LSTM + 1D CNN`æ··åˆæ¨¡å‹ï¼Œç»“åˆäº†`Bi-LSTM`çš„é•¿æœŸä¾èµ–å»ºæ¨¡èƒ½åŠ›å’Œ`1D CNN`çš„å±€éƒ¨ç‰¹å¾æå–èƒ½åŠ›ï¼Œæœ€ç»ˆç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼ˆé€šè¿‡`sigmoid`ç­‰æ¿€æ´»å‡½æ•°è¾“å‡ºæ¦‚ç‡ï¼‰ã€‚è¿™ç§æ··åˆæ¶æ„åœ¨å¤„ç†å¤æ‚åºåˆ—æ•°æ®æ—¶é€šå¸¸è¡¨ç°ä¼˜å¼‚ï¼Œé€‚ç”¨äºæ—¶é—´åºåˆ—ã€ä¿¡å·å¤„ç†ç­‰é¢†åŸŸã€‚å¦‚æœéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå¯ä»¥å¼•å…¥æ®‹å·®è¿æ¥ã€æ³¨æ„åŠ›æœºåˆ¶æˆ–è°ƒæ•´ç½‘ç»œå±‚æ•°å’Œå‚æ•°ã€‚
</p>

### æ„å»ºæ··åˆç¥ç»ç½‘ç»œæ¨¡å‹

<p>

æ„å»ºæ··åˆç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç»“åˆäº† Bi-LSTM å’Œ 1D CNN ä¸¤ä¸ªæ¨¡å‹&lt;/&gt;

``` python
# åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
model = Sequential()
# æ·»åŠ åŒå‘é•¿çŸ­æœŸè®°å¿†å±‚ï¼Œåˆ†åˆ«ä»æ­£å‘å’Œåå‘å¤„ç†è¾“å…¥åºåˆ—ï¼Œæ•æ‰åºåˆ—ä¸­å‰åä¾èµ–å…³ç³»
# æ¯ä¸ªæ–¹å‘æœ‰ 128 ä¸ªéšè—å•å…ƒï¼Œå› æ­¤æ€»å…± 256 ä¸ªéšè—å•å…ƒ
# ä½¿ç”¨æ¿€æ´»å‡½æ•° ReLUï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
model.add(Bidirectional(LSTM(128, activation = 'relu'), input_shape = (X_train.shape[1], X_train.shape[2])))
# æ·»åŠ é‡å¡‘å±‚ï¼Œå°†`Bi-LSTM`çš„è¾“å‡ºé‡å¡‘ä¸ºå½¢çŠ¶ä¸º`(256, 1)`çš„äºŒç»´å¼ é‡
# è¿™ä¸€æ­¥æ˜¯ä¸ºäº†å°†`Bi-LSTM`è¾“å‡ºè°ƒæ•´ä¸ºé€‚åˆåç»­`1D CNN`å±‚å¤„ç†çš„å½¢çŠ¶
model.add(Reshape((256, 1)))
# æ·»åŠ ä¸€ç»´å·ç§¯å±‚`Conv1D`ï¼Œ64 ä¸ªå·ç§¯æ ¸ï¼ˆè¿‡æ»¤å™¨ï¼‰ï¼Œæ¯ä¸ªå·ç§¯æ ¸ä¼šæå–ä¸åŒçš„ç‰¹å¾
# å·ç§¯æ ¸çš„å¤§å°ä¸º 7ï¼Œè¡¨ç¤ºæ¯æ¬¡å·ç§¯æ“ä½œè¦†ç›– 7 ä¸ªæ—¶é—´æ­¥ï¼ˆé€‚ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼‰
# ä½¿ç”¨`ReLU`æ¿€æ´»å‡½æ•°ï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
model.add(Conv1D(filters = 64, kernel_size = 7, activation = 'relu'))
# æ·»åŠ ä¸€ç»´æœ€å¤§æ± åŒ–å±‚ï¼Œæ± åŒ–çª—å£å¤§å°ä¸º 2ï¼Œè¡¨ç¤ºå°†è¾“å…¥æ•°æ®çš„å¤§å°å‡åŠï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼Œæå–ä¸»è¦ç‰¹å¾ï¼Œå‡å°‘è®¡ç®—é‡
model.add(MaxPooling1D(pool_size = 2))
# æ·»åŠ å±•å¹³å±‚ï¼Œå°†å¤šç»´è¾“å…¥ï¼Œä¾‹å¦‚å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾å±•å¹³æˆä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿åç»­å…¨è¿æ¥å±‚å¤„ç†
model.add(Flatten())
# æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
model.add(Dense(32, activation = 'relu'))
# æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
model.add(Dense(16, activation = 'relu'))
# è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
model.add(Dense(1, activation = 'sigmoid'))
```

### ç¼–è¯‘æ¨¡å‹

``` python
# ç¼–è¯‘æ¨¡å‹ï¼Œä¼˜åŒ–å™¨ä¸º adamï¼ŒæŸå¤±å‡½æ•°ä¸ºå‡æ–¹è¯¯å·® (mse)
model.compile(optimizer = 'adam', loss = 'mse')
```

### è®­ç»ƒæ¨¡å‹

``` python
# è®­ç»ƒæ¨¡å‹ï¼Œè®¾ç½® epoch æ¬¡æ•°ä¸º 10ï¼ˆè¿™é‡Œæµ‹è¯•è®¾ç½®å€¼è¾ƒå°ï¼Œå…·ä½“æ ¹æ®å®é™…è®¾ç½®ï¼‰ï¼Œæ‰¹é‡å¤§å°ä¸º 32ï¼Œä½¿ç”¨éªŒè¯é›†è¯„ä¼°æ¨¡å‹
history = model.fit(X_train, y_train, epochs = epoch_size, batch_size = batch_size, validation_data = (X_val, y_val), verbose = verbose)
```

### ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±æ›²çº¿

``` python
plt.figure()
plt.plot(history.history['loss'], c = 'b', label = 'loss')
plt.plot(history.history['val_loss'], c = 'g', label = 'val_loss')
plt.legend()
plt.show()
```

![](/imgs/837a964822c9d4ca0fa71190ec17522f.png)
### ä½¿ç”¨æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹

``` python
y_pred = model.predict(X_test)
```

    ## 
    ## [1m 1/75[0m [37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m9s[0m 132ms/step
    ## [1m18/75[0m [32mâ”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step  
    ## [1m36/75[0m [32mâ”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 3ms/step
    ## [1m55/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”[0m [1m0s[0m 3ms/step
    ## [1m73/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”[0m [1m0s[0m 3ms/step
    ## [1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step
    ## [1m75/75[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 4ms/step

### è®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡

``` python
# è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
mse = metrics.mean_squared_error(y_test, np.array([i for arr in y_pred for i in arr]))
# è®¡ç®—å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
rmse = np.sqrt(mse)
# è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
mae = metrics.mean_absolute_error(y_test, np.array([i for arr in y_pred for i in arr]))
# è®¡ç®— RÂ² æ‹Ÿåˆä¼˜åº¦
r2 = r2_score(y_test, np.array([i for arr in y_pred for i in arr]))

print("å‡æ–¹è¯¯å·® (MSE):", mse)
## å‡æ–¹è¯¯å·® (MSE): 0.0009550017622248667
print("å‡æ–¹æ ¹è¯¯å·® (RMSE):", rmse)
## å‡æ–¹æ ¹è¯¯å·® (RMSE): 0.030903102792840507
print("å¹³å‡ç»å¯¹è¯¯å·® (MAE):", mae)
## å¹³å‡ç»å¯¹è¯¯å·® (MAE): 0.024207261518905218
print("æ‹Ÿåˆä¼˜åº¦:", r2)
## æ‹Ÿåˆä¼˜åº¦: 0.9692174006448219
```

### æ‰“å°æ¨¡å‹ç»“æ„æ‘˜è¦

``` python
model.summary()
## Model: "sequential_1"
## â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
## â”‚ Layer (type)                    â”‚ Output Shape           â”‚       Param # â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ bidirectional_1 (Bidirectional) â”‚ (None, 256)            â”‚       133,120 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ reshape (Reshape)               â”‚ (None, 256, 1)         â”‚             0 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ conv1d (Conv1D)                 â”‚ (None, 250, 64)        â”‚           512 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ max_pooling1d (MaxPooling1D)    â”‚ (None, 125, 64)        â”‚             0 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ flatten (Flatten)               â”‚ (None, 8000)           â”‚             0 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_4 (Dense)                 â”‚ (None, 32)             â”‚       256,032 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_5 (Dense)                 â”‚ (None, 16)             â”‚           528 â”‚
## â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
## â”‚ dense_6 (Dense)                 â”‚ (None, 1)              â”‚            17 â”‚
## â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
##  Total params: 1,170,629 (4.47 MB)
##  Trainable params: 390,209 (1.49 MB)
##  Non-trainable params: 0 (0.00 B)
##  Optimizer params: 780,420 (2.98 MB)
```

### æœªæ¥è¾“å‡ºé¢„æµ‹

``` python
# å–å‡ºé¢„æµ‹çš„æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥
last_output = model.predict(X_test, verbose = verbose)[-1]

# é¢„æµ‹çš„æ—¶é—´æ­¥æ•°
steps = 10  # å‡è®¾å‘åé¢„æµ‹ 10 ä¸ªæ—¶é—´æ­¥
predicted = []
for i in range(steps):
    # å°†æœ€åä¸€ä¸ªè¾“å‡ºåŠ å…¥ X_testï¼Œç»§ç»­å‘åé¢„æµ‹
    input_data = np.append(X_test[-1][1:], last_output).reshape(1, X_test.shape[1], X_test.shape[2])
    # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    next_output = model.predict(input_data, verbose = verbose)
    # å°†é¢„æµ‹çš„å€¼åŠ å…¥ç»“æœåˆ—è¡¨
    predicted.append(next_output[0][0])
    last_output = next_output[0]

print("å‘åé¢„æµ‹çš„å€¼:", predicted)
## å‘åé¢„æµ‹çš„å€¼: [0.53138125, 0.5355914, 0.5394832, 0.54305017, 0.54631245, 0.5493123, 0.55207515, 0.55461955, 0.5569496, 0.55904627]
```

``` python
series_1 = y_pred*(df_max - df_min) + df_min
series_2 = np.array(predicted)*(df_max - df_min) + df_min

plt.figure(figsize = (15,4), dpi = 300)

plt.subplot(3 ,1, 1)
plt.plot(train_set, color = 'c', label = 'Training Data')
plt.plot(val_set, color = 'r', label = 'Validation Data')
plt.plot(test_set, color = 'b', label = 'Testing Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.legend()

plt.subplot(3, 1, 2)
plt.plot(test_set, color = 'b', label = 'Training Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.legend()

plt.subplot(3, 1, 3)
plt.plot(test_set, color = 'b', label = 'Training Data')
plt.plot(pd.date_range(start = '2016-08-12', end = '2023-03-01', freq = 'D'), series_1, color = 'y', label = 'Testing Data Predition')
plt.plot(pd.date_range(start = '2023-03-02', end = '2023-03-11', freq = 'D'), series_2, color = 'magenta', linestyle = '-.', label = 'Futrue Prediction')
plt.xlim(pd.Timestamp('2022-01-01'), pd.Timestamp('2023-03-11'))
## (18993.0, 19427.0)
plt.legend()

plt.show()
```

![](/imgs/c9443de57904c22f0f997c57bd68e8a4.png)
# ç‰ˆæœ¬ä¿¡æ¯

``` python
import sys
import platform
import pkg_resources

def session_info():
    print("Python Session Information")
    print("==========================")
    
    # Python ç‰ˆæœ¬ä¿¡æ¯
    print(f"Python Version: {sys.version}")
    print(f"Python Implementation: {platform.python_implementation()}")
    print(f"Python Build: {platform.python_build()}")
    
    # æ“ä½œç³»ç»Ÿä¿¡æ¯
    print("\nOperating System Information")
    print(f"OS: {platform.system()}")
    print(f"OS Release: {platform.release()}")
    print(f"OS Version: {platform.version()}")
    print(f"Machine: {platform.machine()}")
    print(f"Processor: {platform.processor()}")
    
    # å·²å®‰è£…çš„åŒ…åŠå…¶ç‰ˆæœ¬
    print("\nInstalled Packages")
    print("------------------")
    installed_packages = sorted(
        [(dist.key, dist.version) for dist in pkg_resources.working_set],
        key=lambda x: x[0].lower()
    )
    for package, version in installed_packages:
        print(f"{package}: {version}")

# è°ƒç”¨å‡½æ•°
session_info()
## Python Session Information
## ==========================
## Python Version: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]
## Python Implementation: CPython
## Python Build: ('main', 'Apr  4 2022 05:22:27')
## 
## Operating System Information
## OS: Windows
## OS Release: 10
## OS Version: 10.0.26100
## Machine: AMD64
## Processor: Intel64 Family 6 Model 151 Stepping 2, GenuineIntel
## 
## Installed Packages
## ------------------
## absl-py: 2.2.2
## aiohttp: 3.8.1
## aiosignal: 1.2.0
## alabaster: 0.7.12
## anaconda-client: 1.9.0
## anaconda-navigator: 2.1.4
## anaconda-project: 0.10.2
## anyio: 3.5.0
## appdirs: 1.4.4
## argon2-cffi: 21.3.0
## argon2-cffi-bindings: 21.2.0
## arrow: 1.2.2
## astroid: 2.6.6
## astropy: 5.0.4
## asttokens: 2.0.5
## astunparse: 1.6.3
## async-timeout: 4.0.1
## atomicwrites: 1.4.0
## attrs: 21.4.0
## automat: 20.2.0
## autopep8: 1.6.0
## babel: 2.9.1
## backcall: 0.2.0
## backports.functools-lru-cache: 1.6.4
## backports.tempfile: 1.0
## backports.weakref: 1.0.post1
## bcrypt: 3.2.0
## beautifulsoup4: 4.11.1
## binaryornot: 0.4.4
## biopython: 1.79
## bitarray: 2.4.1
## bkcharts: 0.2
## black: 19.10b0
## bleach: 4.1.0
## bokeh: 2.4.2
## boto3: 1.21.32
## botocore: 1.24.32
## bottleneck: 1.3.4
## brotlipy: 0.7.0
## cachetools: 4.2.2
## causal-learn: 0.1.4.1
## certifi: 2021.10.8
## cffi: 1.15.0
## chardet: 4.0.0
## charset-normalizer: 2.0.4
## clarabel: 0.10.0
## click: 8.0.4
## cloudpickle: 2.0.0
## clyent: 1.2.2
## colorama: 0.4.4
## colorcet: 2.0.6
## comtypes: 1.1.10
## conda: 4.12.0
## conda-build: 3.21.8
## conda-content-trust: 0+unknown
## conda-pack: 0.6.0
## conda-package-handling: 1.8.1
## conda-repo-cli: 1.0.4
## conda-token: 0.3.0
## conda-verify: 3.4.2
## constantly: 15.1.0
## cookiecutter: 1.7.3
## cryptography: 3.4.8
## cssselect: 1.1.0
## cvxpy: 1.6.5
## cycler: 0.11.0
## cython: 0.29.28
## cytoolz: 0.11.0
## daal4py: 2021.5.0
## dask: 2022.2.1
## datashader: 0.13.0
## datashape: 0.5.4
## debugpy: 1.5.1
## decorator: 5.1.1
## defusedxml: 0.7.1
## diff-match-patch: 20200713
## distributed: 2022.2.1
## docutils: 0.17.1
## docxcompose: 1.4.0
## docxtpl: 0.19.1
## dowhy: 0.12
## entrypoints: 0.4
## et-xmlfile: 1.1.0
## executing: 0.8.3
## fastjsonschema: 2.15.1
## filelock: 3.6.0
## flake8: 3.9.2
## flask: 1.1.2
## flatbuffers: 25.2.10
## fonttools: 4.25.0
## frozenlist: 1.2.0
## fsspec: 2022.2.0
## future: 0.18.2
## gast: 0.6.0
## gensim: 4.1.2
## glob2: 0.7
## google-api-core: 1.25.1
## google-auth: 1.33.0
## google-cloud-core: 1.7.1
## google-cloud-storage: 1.31.0
## google-crc32c: 1.1.2
## google-pasta: 0.2.0
## google-resumable-media: 1.3.1
## googleapis-common-protos: 1.53.0
## graphviz: 0.20.3
## greenlet: 1.1.1
## grpcio: 1.71.0
## h5py: 3.13.0
## heapdict: 1.0.1
## holoviews: 1.14.8
## hvplot: 0.7.3
## hyperlink: 21.0.0
## idna: 3.3
## imagecodecs: 2021.8.26
## imageio: 2.9.0
## imagesize: 1.3.0
## importlib-metadata: 4.11.3
## incremental: 21.3.0
## inflection: 0.5.1
## iniconfig: 1.1.1
## intake: 0.6.5
## intervaltree: 3.1.0
## ipykernel: 6.9.1
## ipython: 8.2.0
## ipython-genutils: 0.2.0
## ipywidgets: 7.6.5
## isort: 5.9.3
## itemadapter: 0.3.0
## itemloaders: 1.0.4
## itsdangerous: 2.0.1
## jdcal: 1.4.1
## jedi: 0.18.1
## jinja2: 2.11.3
## jinja2-time: 0.2.0
## jmespath: 0.10.0
## joblib: 1.4.2
## json5: 0.9.6
## jsonschema: 4.4.0
## jupyter: 1.0.0
## jupyter-client: 6.1.12
## jupyter-console: 6.4.0
## jupyter-core: 4.9.2
## jupyter-server: 1.13.5
## jupyterlab: 3.3.2
## jupyterlab-pygments: 0.1.2
## jupyterlab-server: 2.10.3
## jupyterlab-widgets: 1.0.0
## keras: 3.9.2
## keyring: 23.4.0
## kiwisolver: 1.3.2
## lazy-object-proxy: 1.6.0
## libarchive-c: 2.9
## libclang: 18.1.1
## lightgbm: 4.6.0
## llvmlite: 0.43.0
## locket: 0.2.1
## looseversion: 1.3.0
## lxml: 4.8.0
## markdown: 3.3.4
## markdown-it-py: 3.0.0
## markupsafe: 2.0.1
## matplotlib: 3.5.1
## matplotlib-inline: 0.1.2
## mccabe: 0.6.1
## mdurl: 0.1.2
## menuinst: 1.4.18
## mistune: 0.8.4
## mkl-fft: 1.3.1
## mkl-random: 1.2.2
## mkl-service: 2.4.0
## ml-dtypes: 0.5.1
## mock: 4.0.3
## momentchi2: 0.1.8
## mpmath: 1.2.1
## msgpack: 1.0.2
## multidict: 5.1.0
## multipledispatch: 0.6.0
## munkres: 1.1.4
## mypy-extensions: 0.4.3
## namex: 0.0.9
## navigator-updater: 0.2.1
## nbclassic: 0.3.5
## nbclient: 0.5.13
## nbconvert: 6.4.4
## nbformat: 5.3.0
## nest-asyncio: 1.5.5
## networkx: 3.2.1
## nltk: 3.7
## nose: 1.3.7
## notebook: 6.4.8
## numba: 0.60.0
## numexpr: 2.8.1
## numpy: 1.26.4
## numpydoc: 1.2
## olefile: 0.46
## opencv-python: 4.11.0.86
## openpyxl: 3.0.9
## opt-einsum: 3.4.0
## optree: 0.15.0
## osqp: 1.0.3
## packaging: 21.3
## pandas: 1.5.3
## pandocfilters: 1.5.0
## panel: 0.13.0
## param: 1.12.0
## paramiko: 2.8.1
## parsel: 1.6.0
## parso: 0.8.3
## partd: 1.2.0
## pathspec: 0.7.0
## patsy: 1.0.1
## pep8: 1.7.1
## pexpect: 4.8.0
## pickleshare: 0.7.5
## pillow: 9.0.1
## pims: 0.7
## pip: 21.2.4
## pkginfo: 1.8.2
## plotly: 5.6.0
## pluggy: 1.0.0
## poyo: 0.5.0
## prometheus-client: 0.13.1
## prompt-toolkit: 3.0.20
## protego: 0.1.16
## protobuf: 5.29.4
## psutil: 5.8.0
## ptyprocess: 0.7.0
## pure-eval: 0.2.2
## py: 1.11.0
## pyasn1: 0.4.8
## pyasn1-modules: 0.2.8
## pycodestyle: 2.7.0
## pycosat: 0.6.3
## pycparser: 2.21
## pyct: 0.4.6
## pycurl: 7.44.1
## pydispatcher: 2.0.5
## pydocstyle: 6.1.1
## pydot: 3.0.4
## pyerfa: 2.0.0
## pyflakes: 2.3.1
## pygments: 2.19.1
## pyhamcrest: 2.0.2
## pyjwt: 2.1.0
## pylint: 2.9.6
## pyls-spyder: 0.4.0
## pymysql: 1.1.1
## pynacl: 1.4.0
## pyodbc: 4.0.32
## pyopenssl: 21.0.0
## pyparsing: 3.2.3
## pypdf2: 3.0.1
## pyreadline: 2.1
## pyrsistent: 0.18.0
## pysocks: 1.7.1
## pytest: 7.1.1
## python-dateutil: 2.8.2
## python-docx: 1.1.2
## python-lsp-black: 1.0.0
## python-lsp-jsonrpc: 1.0.0
## python-lsp-server: 1.2.4
## python-slugify: 5.0.2
## python-snappy: 0.6.0
## pytz: 2021.3
## pyviz-comms: 2.0.2
## pywavelets: 1.3.0
## pywin32: 302
## pywin32-ctypes: 0.2.0
## pywinpty: 2.0.2
## pyyaml: 6.0
## pyzmq: 22.3.0
## qdarkstyle: 3.0.2
## qstylizer: 0.1.10
## qtawesome: 1.0.3
## qtconsole: 5.3.0
## qtpy: 2.0.1
## queuelib: 1.5.0
## regex: 2022.3.15
## requests: 2.27.1
## requests-file: 1.5.1
## rich: 14.0.0
## rope: 0.22.0
## rsa: 4.7.2
## rtree: 0.9.7
## ruamel-yaml-conda: 0.15.100
## s3transfer: 0.5.0
## scikit-image: 0.19.2
## scikit-learn: 1.6.1
## scikit-learn-intelex: 2021.20220215.102710
## scipy: 1.13.1
## scrapy: 2.6.1
## scs: 3.2.7.post2
## seaborn: 0.11.2
## send2trash: 1.8.0
## service-identity: 18.1.0
## setuptools: 61.2.0
## shap: 0.47.2
## sip: 4.19.13
## six: 1.16.0
## slicer: 0.0.8
## slicerator: 1.1.0
## smart-open: 5.1.0
## sniffio: 1.2.0
## snowballstemmer: 2.2.0
## sortedcollections: 2.1.0
## sortedcontainers: 2.4.0
## soupsieve: 2.3.1
## sphinx: 4.4.0
## sphinxcontrib-applehelp: 1.0.2
## sphinxcontrib-devhelp: 1.0.2
## sphinxcontrib-htmlhelp: 2.0.0
## sphinxcontrib-jsmath: 1.0.1
## sphinxcontrib-qthelp: 1.0.3
## sphinxcontrib-serializinghtml: 1.1.5
## spyder: 5.1.5
## spyder-kernels: 2.1.3
## sqlalchemy: 1.4.32
## stack-data: 0.2.0
## statsmodels: 0.14.4
## sympy: 1.13.3
## tables: 3.6.1
## tabulate: 0.8.9
## tbb: 0.2
## tblib: 1.7.0
## tenacity: 8.0.1
## tensorboard: 2.19.0
## tensorboard-data-server: 0.7.2
## tensorflow: 2.19.0
## tensorflow-io-gcs-filesystem: 0.31.0
## termcolor: 3.1.0
## terminado: 0.13.1
## testpath: 0.5.0
## text-unidecode: 1.3
## textdistance: 4.2.1
## threadpoolctl: 3.6.0
## three-merge: 0.1.1
## tifffile: 2021.7.2
## tinycss: 0.4
## tldextract: 3.2.0
## toml: 0.10.2
## tomli: 1.2.2
## toolz: 0.11.2
## torch: 2.7.0+cu128
## torchaudio: 2.7.0+cu128
## torchvision: 0.22.0+cu128
## tornado: 6.1
## tqdm: 4.64.0
## trackpy: 0.5.0
## traitlets: 5.1.1
## twisted: 22.2.0
## twisted-iocpsupport: 1.0.2
## typed-ast: 1.4.3
## typing-extensions: 4.13.1
## ujson: 5.1.0
## unidecode: 1.2.0
## urllib3: 1.26.9
## w3lib: 1.21.0
## watchdog: 2.1.6
## wcwidth: 0.2.5
## webencodings: 0.5.1
## websocket-client: 0.58.0
## werkzeug: 2.0.3
## wheel: 0.37.1
## widgetsnbextension: 3.5.2
## win-inet-pton: 1.1.0
## win-unicode-console: 0.5
## wincertstore: 0.2
## wrapt: 1.12.1
## xarray: 0.20.1
## xgboost: 2.1.4
## xlrd: 2.0.1
## xlsxwriter: 3.0.3
## xlwings: 0.24.9
## yapf: 0.31.0
## yarl: 1.6.3
## zict: 2.0.0
## zipp: 3.7.0
## zope.interface: 5.4.0
```

# ä»£ç ç®€æ´ç‰ˆ

``` python
import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.metrics import r2_score
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import Reshape
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Bidirectional, Dense
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.layers import Add

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ£€æµ‹æ˜¯å¦æ”¯æŒ GPU åŠ é€Ÿè¿ç®—
def check_tensorflow_gpu():
    print("TensorFlow ç‰ˆæœ¬:", tf.__version__)
    if tf.test.is_gpu_available():
        print("GPU is available")
    else:
        print("GPU is not available, using CPU")

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå¯¹æ•°æ®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
def normalize_dataframe(DFTrain, DFTest):
    # åˆ›å»º MinMaxScaler å¯¹è±¡ï¼Œç”¨äºå°†æ•°æ®å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´
    scaler = MinMaxScaler()
    # åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆå½’ä¸€åŒ–æ¨¡å‹ï¼Œè®¡ç®—æ¯ä¸ªç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼
    scaler.fit(DFTrain)
    # å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†åº”ç”¨å½’ä¸€åŒ–å˜æ¢ï¼Œå¹¶ä¿ç•™åŸå§‹æ•°æ®çš„åˆ—åå’Œç´¢å¼•
    train_data = pd.DataFrame(scaler.transform(DFTrain), columns = DFTrain.columns, index = DFTrain.index)
    test_data = pd.DataFrame(scaler.transform(DFTest), columns = DFTest.columns, index = DFTest.index)
    
    # è¿”å›å½’ä¸€åŒ–åçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    return train_data, test_data

# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºå‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œå°†å…¶è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹è¾“å…¥çš„æ ¼å¼
def prepare_data(data, win_size):
    X = []  # å­˜å‚¨è¾“å…¥ç‰¹å¾ï¼ˆæ—¶é—´çª—å£å†…çš„æ•°æ®ï¼‰
    y = []  # å­˜å‚¨ç›®æ ‡å€¼ï¼ˆæ—¶é—´çª—å£åçš„æ•°æ®ï¼‰

    # éå†æ•°æ®ï¼Œåˆ›å»ºæ—¶é—´çª—å£å¤§å°ä¸º win_size çš„è¾“å…¥å’Œå¯¹åº”çš„ç›®æ ‡å€¼
    for i in range(len(data) - win_size):
        # æå–ä¸€ä¸ªæ—¶é—´çª—å£çš„æ•°æ®ä½œä¸ºè¾“å…¥
        temp_x = data[i:i + win_size]
        # æå–æ—¶é—´çª—å£åçš„æ•°æ®ä½œä¸ºç›®æ ‡å€¼
        temp_y = data[i + win_size]
        X.append(temp_x)
        y.append(temp_y)

    # å°†åˆ—è¡¨è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œä¾¿äºåç»­æ¨¡å‹è¾“å…¥
    X = np.asarray(X)
    y = np.asarray(y)
    
    # è¿”å›è¾“å…¥ç‰¹å¾å’Œç›®æ ‡å€¼
    return X, y



if __name__ == '__main__':
    
    # å…¨å±€ç¯å¢ƒå˜é‡
    win_size = 30                 # å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œè®¾ç½®æ—¶é—´çª—å£å¤§å°ä¸º 30
    tra_val_ratio = 0.7           # æµ‹è¯•å’Œè®­ç»ƒé›†æ¯”ä¾‹
    epoch_size = 10               # è®¾ç½® epoch æ¬¡æ•°ä¸º 10ï¼ˆè¿™é‡Œæµ‹è¯•è®¾ç½®å€¼è¾ƒå°ï¼Œå…·ä½“æ ¹æ®å®é™…è®¾ç½®ï¼‰
    batch_size = 32               # è®¾ç½®æ‰¹é‡å¤§å°
    verbose = 0                   # æ˜¯å¦æ‰“å°ä¸­é—´è¿‡ç¨‹ï¼Œ0 è¡¨ç¤ºé™é»˜çŠ¶æ€
    
    # è®¾ç½®å·¥ä½œç›®å½•
    wkdir = 'E:/BaiduSyncdisk/005.Bioinformatics/Bioinformatics/src/250508_multiple_timeseries_model'
    os.chdir(wkdir)
    
    # è®¾ç½®éšæœºç§å­
    SEED = 42
    random.seed(SEED)
    np.random.seed(SEED)
    tf.set_random_seed(SEED)
    
    # å¢å¼º TensorFlow çš„ç¡®å®šæ€§
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'

    # åŠ è½½æ•°æ®
    # è¯»å– Excel æ–‡ä»¶ï¼Œè®¾ç½®ç¬¬ä¸€åˆ—ä¸ºç´¢å¼•ï¼Œå¹¶è§£ææ—¥æœŸåˆ—
    DF = pd.read_excel('data/data.xlsx', index_col = 0, parse_dates = ['æ—¥æœŸ'])
    # æå–`å¹³å‡æ°£æº«`åˆ—ä½œä¸ºç ”ç©¶å¯¹è±¡
    DF = DF[['å¹³å‡æ°£æº«']]
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    DFTrain = DF[DF.index < '2020-01-01']
    DFTest = DF[DF.index >= '2020-01-01']

    # å¯è§†åŒ–è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®
    plt.figure(figsize = (15, 5))
    plt.subplot(1, 2, 1)
    plt.plot(DFTrain['å¹³å‡æ°£æº«'], color = 'b',  alpha = 0.5)
    plt.title('Train Data')
    plt.xticks(rotation = 0)
    plt.grid(True)
    plt.subplot(1, 2, 2)
    plt.plot(DFTest['å¹³å‡æ°£æº«'], color = 'r',  alpha = 0.5)
    plt.title('Test Data')
    plt.grid(True)
    plt.xticks(rotation = 0)
    plt.show()

    # å¯¹è®­ç»ƒé›†å’Œæµ‹è¯•é›†è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
    data_train, data_test = normalize_dataframe(DFTrain, DFTest)
    
    # å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®ï¼Œè®¾ç½®æ—¶é—´çª—å£å¤§å°ä¸º 30
    X, y = prepare_data(data_train.values, win_size)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå½“å€¼ä¸º 0.7 åˆ™è¡¨ç¤º 70% ä¸ºè®­ç»ƒé›†ï¼Œ30% ä¸ºéªŒè¯é›†
    train_size = int(len(X) * tra_val_ratio)  
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„è¾“å…¥ç‰¹å¾
    X_train, X_val = X[:train_size], X[train_size:]
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç›®æ ‡å€¼
    y_train, y_val = y[:train_size], y[train_size:]
    
    # å‡†å¤‡æµ‹è¯•é›†æ•°æ®ï¼Œå°†æµ‹è¯•æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
    X_test, y_test = prepare_data(data_test.values, win_size)
    
    # æ‰“å°å„æ•°æ®é›†çš„å½¢çŠ¶ï¼Œä¾¿äºæ£€æŸ¥
    print("è®­ç»ƒé›†å½¢çŠ¶:", X_train.shape, y_train.shape)
    print("éªŒè¯é›†å½¢çŠ¶:", X_val.shape, y_val.shape)
    print("æµ‹è¯•é›†å½¢çŠ¶:", X_test.shape, y_test.shape)

    # æ„å»º Bi-LSTM æ¨¡å‹ï¼ŒåŒå‘é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œ
    if False:
        
        # åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
        model = Sequential()
        # æ·»åŠ åŒå‘ LSTM å±‚ï¼Œ128 ä¸ªå•å…ƒï¼Œæ¿€æ´»å‡½æ•°ä¸º reluï¼Œè¾“å…¥å½¢çŠ¶ä¸º (æ—¶é—´çª—å£å¤§å°, ç‰¹å¾æ•°é‡)
        model.add(Bidirectional(LSTM(128, activation = 'relu'), input_shape = (X_train.shape[1], X_train.shape[2])))
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ64 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(64, activation = 'relu'))
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(32, activation = 'relu'))
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(16, activation = 'relu'))
        # è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
        model.add(Dense(1, activation = 'sigmoid'))
    
    # æ„å»º 1D CNN æ¨¡å‹ï¼Œä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œ
    elif False:
        
        # åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
        model = Sequential()
        # æ·»åŠ ä¸€ç»´å·ç§¯å±‚`Conv1D`ï¼Œ64 ä¸ªå·ç§¯æ ¸ï¼ˆè¿‡æ»¤å™¨ï¼‰ï¼Œæ¯ä¸ªå·ç§¯æ ¸ä¼šæå–ä¸åŒçš„ç‰¹å¾
        # å·ç§¯æ ¸çš„å¤§å°ä¸º 7ï¼Œè¡¨ç¤ºæ¯æ¬¡å·ç§¯æ“ä½œè¦†ç›– 7 ä¸ªæ—¶é—´æ­¥ï¼ˆé€‚ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼‰
        # ä½¿ç”¨`ReLU`æ¿€æ´»å‡½æ•°ï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
        model.add(Conv1D(filters = 64, kernel_size = 7, activation = 'relu', input_shape = (X_train.shape[1], X_train.shape[2])))
        # æ·»åŠ ä¸€ç»´æœ€å¤§æ± åŒ–å±‚ï¼Œæ± åŒ–çª—å£å¤§å°ä¸º 2ï¼Œè¡¨ç¤ºå°†è¾“å…¥æ•°æ®çš„å¤§å°å‡åŠï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼Œæå–ä¸»è¦ç‰¹å¾ï¼Œå‡å°‘è®¡ç®—é‡
        model.add(MaxPooling1D(pool_size = 2))
        # æ·»åŠ å±•å¹³å±‚ï¼Œå°†å¤šç»´è¾“å…¥ï¼Œä¾‹å¦‚å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾å±•å¹³æˆä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿åç»­å…¨è¿æ¥å±‚å¤„ç†
        model.add(Flatten())
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(32, activation = 'relu'))
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(16, activation = 'relu'))
        # è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
        model.add(Dense(1, activation = 'sigmoid'))
       
    # æ„å»ºæ··åˆç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç»“åˆäº† Bi-LSTM å’Œ 1D CNN ä¸¤ä¸ªæ¨¡å‹
    elif False:
        
        # åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
        model = Sequential()
        # æ·»åŠ åŒå‘é•¿çŸ­æœŸè®°å¿†å±‚ï¼Œåˆ†åˆ«ä»æ­£å‘å’Œåå‘å¤„ç†è¾“å…¥åºåˆ—ï¼Œæ•æ‰åºåˆ—ä¸­å‰åä¾èµ–å…³ç³»
        # æ¯ä¸ªæ–¹å‘æœ‰ 128 ä¸ªéšè—å•å…ƒï¼Œå› æ­¤æ€»å…± 256 ä¸ªéšè—å•å…ƒ
        # ä½¿ç”¨æ¿€æ´»å‡½æ•° ReLUï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
        model.add(Bidirectional(LSTM(128, activation = 'relu'), input_shape = (X_train.shape[1], X_train.shape[2])))
        # æ·»åŠ é‡å¡‘å±‚ï¼Œå°†`Bi-LSTM`çš„è¾“å‡ºé‡å¡‘ä¸ºå½¢çŠ¶ä¸º`(256, 1)`çš„äºŒç»´å¼ é‡
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†å°†`Bi-LSTM`è¾“å‡ºè°ƒæ•´ä¸ºé€‚åˆåç»­`1D CNN`å±‚å¤„ç†çš„å½¢çŠ¶
        model.add(Reshape((256, 1)))
        # æ·»åŠ ä¸€ç»´å·ç§¯å±‚`Conv1D`ï¼Œ64 ä¸ªå·ç§¯æ ¸ï¼ˆè¿‡æ»¤å™¨ï¼‰ï¼Œæ¯ä¸ªå·ç§¯æ ¸ä¼šæå–ä¸åŒçš„ç‰¹å¾
        # å·ç§¯æ ¸çš„å¤§å°ä¸º 7ï¼Œè¡¨ç¤ºæ¯æ¬¡å·ç§¯æ“ä½œè¦†ç›– 7 ä¸ªæ—¶é—´æ­¥ï¼ˆé€‚ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼‰
        # ä½¿ç”¨`ReLU`æ¿€æ´»å‡½æ•°ï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
        model.add(Conv1D(filters = 64, kernel_size = 7, activation = 'relu'))
        # æ·»åŠ ä¸€ç»´æœ€å¤§æ± åŒ–å±‚ï¼Œæ± åŒ–çª—å£å¤§å°ä¸º 2ï¼Œè¡¨ç¤ºå°†è¾“å…¥æ•°æ®çš„å¤§å°å‡åŠï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼Œæå–ä¸»è¦ç‰¹å¾ï¼Œå‡å°‘è®¡ç®—é‡
        model.add(MaxPooling1D(pool_size = 2))
        # æ·»åŠ å±•å¹³å±‚ï¼Œå°†å¤šç»´è¾“å…¥ï¼Œä¾‹å¦‚å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾å±•å¹³æˆä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿åç»­å…¨è¿æ¥å±‚å¤„ç†
        model.add(Flatten())
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(32, activation = 'relu'))
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        model.add(Dense(16, activation = 'relu'))
        # è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
        model.add(Dense(1, activation = 'sigmoid'))
        
    # æ„å»ºæ··åˆç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œç»“åˆäº† Bi-LSTM å’Œ 1D CNN ä»¥åŠæ®‹å·®ç½‘ç»œ
    else:
        
        # å®šä¹‰æ®‹å·®å—å‡½æ•°
        def residual_block(input_layer, filters, kernel_size):
            # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
            # `filters`ï¼ŒæŒ‡å®šå·ç§¯æ ¸æ•°é‡ï¼Œå®šä¹‰ç‰¹å¾æå–çš„ç»´åº¦
            # `kernel_size`ï¼Œå·ç§¯æ ¸å¤§å°ï¼Œå®šä¹‰æ¯æ¬¡å·ç§¯æ“ä½œè¦†ç›–çš„æ—¶é—´æ­¥é•¿
            # `activation = 'relu'`ï¼Œæ¿€æ´»å‡½æ•°ï¼Œä½¿ç”¨`RuLU`æ¿€æ´»å‡½æ•°ï¼Œå¼•å…¥éçº¿æ€§
            # `padding = 'same'`ï¼Œä½¿ç”¨ same å¡«å……ï¼Œç¡®ä¿è¾“å‡ºå½¢çŠ¶ä¸è¾“å…¥å½¢çŠ¶ç›¸åŒï¼Œä¾¿äºæ®‹å·®è¿æ¥
            residual = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu', padding = 'same')(input_layer)
            # ç¬¬äºŒä¸ªå·ç§¯å±‚
            # ç»§ç»­è¿›è¡Œç‰¹å¾å¤„ç†ï¼Œå‚æ•°ä¸ç¬¬ä¸€ä¸ªå·ç§¯å±‚ç›¸åŒ
            residual = Conv1D(filters = filters, kernel_size = kernel_size, activation = 'relu', padding = 'same')(residual)
            # æ®‹å·®è¿æ¥ï¼Œå°†è¾“å…¥å±‚ä¸ç»è¿‡ä¸¤ä¸ªå·ç§¯å±‚å¤„ç†çš„è¾“å‡ºç›¸åŠ ï¼Œå½¢æˆæ®‹å·®è¿æ¥
            # æ®‹å·®æ‹¼æ¥æœ‰åŠ©äºç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¢å¼ºæ·±å±‚ç½‘ç»œçš„è®­ç»ƒæ•ˆæœ
            residual = Add()([input_layer, residual])
            
            return residual

        # åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹
        model = Sequential()
        # æ·»åŠ åŒå‘é•¿çŸ­æœŸè®°å¿†å±‚ï¼Œåˆ†åˆ«ä»æ­£å‘å’Œåå‘å¤„ç†è¾“å…¥åºåˆ—ï¼Œæ•æ‰åºåˆ—ä¸­å‰åä¾èµ–å…³ç³»
        # æ¯ä¸ªæ–¹å‘æœ‰ 128 ä¸ªéšè—å•å…ƒï¼Œå› æ­¤æ€»å…± 256 ä¸ªéšè—å•å…ƒ
        # ä½¿ç”¨æ¿€æ´»å‡½æ•° ReLUï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
        model.add(Bidirectional(LSTM(128, activation = 'relu'), input_shape = (X_train.shape[1], X_train.shape[2])))
        # æ·»åŠ é‡å¡‘å±‚ï¼Œå°†`Bi-LSTM`çš„è¾“å‡ºé‡å¡‘ä¸ºå½¢çŠ¶ä¸º`(256, 1)`çš„äºŒç»´å¼ é‡
        # è¿™ä¸€æ­¥æ˜¯ä¸ºäº†å°†`Bi-LSTM`è¾“å‡ºè°ƒæ•´ä¸ºé€‚åˆåç»­`1D CNN`å±‚å¤„ç†çš„å½¢çŠ¶
        model.add(Reshape((256, 1)))
        # æ·»åŠ ä¸€ç»´å·ç§¯å±‚`Conv1D`ï¼Œ64 ä¸ªå·ç§¯æ ¸ï¼ˆè¿‡æ»¤å™¨ï¼‰ï¼Œæ¯ä¸ªå·ç§¯æ ¸ä¼šæå–ä¸åŒçš„ç‰¹å¾
        # å·ç§¯æ ¸çš„å¤§å°ä¸º 7ï¼Œè¡¨ç¤ºæ¯æ¬¡å·ç§¯æ“ä½œè¦†ç›– 7 ä¸ªæ—¶é—´æ­¥ï¼ˆé€‚ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼‰
        # ä½¿ç”¨`ReLU`æ¿€æ´»å‡½æ•°ï¼Œå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›
        model.add(Conv1D(filters = 64, kernel_size = 7, activation = 'relu'))
        # æ·»åŠ ä¸€ç»´æœ€å¤§æ± åŒ–å±‚ï¼Œæ± åŒ–çª—å£å¤§å°ä¸º 2ï¼Œè¡¨ç¤ºå°†è¾“å…¥æ•°æ®çš„å¤§å°å‡åŠï¼ˆä¸‹é‡‡æ ·ï¼‰ï¼Œæå–ä¸»è¦ç‰¹å¾ï¼Œå‡å°‘è®¡ç®—é‡
        model.add(MaxPooling1D(pool_size = 2))
        # è·å–å½“å‰æ¨¡å‹çš„ä¸­é—´è¾“å‡ºï¼Œç”¨äºåç»­æ®‹å·®å—çš„è¾“å…¥
        intermediate_output = model.layers[-1].output
        # è°ƒç”¨æ®‹å·®å—å‡½æ•°ï¼Œæ„å»ºæ®‹å·®å—
        # å°†`MaxPooling1D()`çš„è¾“å…¥ä¼ å…¥æ®‹å·®å—
        residual_output = residual_block(model.layers[-1].output, filters = 64, kernel_size = 7)
        # å¯¹æ®‹å·®å—è¾“å‡ºè¿›è¡Œæœ€å¤§æ± åŒ–æ“ä½œï¼Œç»§ç»­ä¸‹é‡‡æ ·ï¼Œè¿›ä¸€æ­¥å‡å°‘ç»´åº¦
        residual_output = MaxPooling1D(pool_size = 2)(residual_output)
        # æ·»åŠ å±•å¹³å±‚ï¼Œå°†å¤šç»´è¾“å…¥å±•å¹³æˆä¸€ç»´å‘é‡ï¼Œä»¥ä¾¿åç»­å…¨è¿æ¥å±‚å¤„ç†
        residual_output = Flatten()(residual_output)
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ32 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        residual_output = Dense(32, activation = 'relu')(residual_output)
        # æ·»åŠ å…¨è¿æ¥å±‚ï¼Œ16 ä¸ªç¥ç»å…ƒï¼Œrelu æ¿€æ´»å‡½æ•°
        residual_output = Dense(16, activation = 'relu')(residual_output)
        # è¾“å‡ºå±‚ï¼Œ1 ä¸ªç¥ç»å…ƒï¼Œç”¨äºé¢„æµ‹å•ä¸ªæ•°å€¼ï¼›ä½¿ç”¨ sigmoid æ¿€æ´»å‡½æ•°ï¼Œå°†è¾“å‡ºé™åˆ¶åœ¨ 0 åˆ° 1 ä¹‹é—´
        output_layer = Dense(1, activation = 'sigmoid')(residual_output)
        # æ„å»ºæœ€ç»ˆæ¨¡å‹
        # ä½¿ç”¨`Model`å°†æ•´ä¸ªç½‘ç»œè¿æ¥èµ·æ¥ï¼Œå…è®¸éé¡ºåºç»“æ„ï¼Œå¦‚æ®‹å·®è¿æ¥
        model = Model(inputs = model.input, outputs = output_layer)
    
        
    # ç¼–è¯‘æ¨¡å‹ï¼Œä¼˜åŒ–å™¨ä¸º adamï¼ŒæŸå¤±å‡½æ•°ä¸ºå‡æ–¹è¯¯å·® (mse)
    model.compile(optimizer = 'adam', loss = 'mse')
    
    # è®­ç»ƒæ¨¡å‹ï¼Œè®¾ç½® epoch æ¬¡æ•°ä¸º 10ï¼Œæ‰¹é‡å¤§å°ä¸º 32ï¼Œä½¿ç”¨éªŒè¯é›†è¯„ä¼°æ¨¡å‹
    history = model.fit(X_train, y_train, epochs = epoch_size, batch_size = batch_size, validation_data = (X_val, y_val), verbose = verbose)
    
    # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±æ›²çº¿
    plt.figure()
    plt.plot(history.history['loss'], c = 'b', label = 'loss')
    plt.plot(history.history['val_loss'], c = 'g', label = 'val_loss')
    plt.legend()
    plt.show()
    
    # ä½¿ç”¨æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
    y_pred = model.predict(X_test)
    
    # è®¡ç®—æ¨¡å‹æ€§èƒ½æŒ‡æ ‡
    # è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰
    mse = metrics.mean_squared_error(y_test, np.array([i for arr in y_pred for i in arr]))
    # è®¡ç®—å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰
    rmse = np.sqrt(mse)
    # è®¡ç®—å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
    mae = metrics.mean_absolute_error(y_test, np.array([i for arr in y_pred for i in arr]))
    # è®¡ç®— RÂ² æ‹Ÿåˆä¼˜åº¦
    r2 = r2_score(y_test, np.array([i for arr in y_pred for i in arr]))
    
    print("å‡æ–¹è¯¯å·® (MSE):", mse)
    print("å‡æ–¹æ ¹è¯¯å·® (RMSE):", rmse)
    print("å¹³å‡ç»å¯¹è¯¯å·® (MAE):", mae)
    print("æ‹Ÿåˆä¼˜åº¦:", r2)
            
    # æ‰“å°æ¨¡å‹ç»“æ„æ‘˜è¦
    model.summary()

    # è·å–å½“å‰ç¯å¢ƒä¿¡æ¯
    import sys
    import platform
    import pkg_resources
    
    def session_info():
        print("Python Session Information")
        print("==========================")
        
        # Python ç‰ˆæœ¬ä¿¡æ¯
        print(f"Python Version: {sys.version}")
        print(f"Python Implementation: {platform.python_implementation()}")
        print(f"Python Build: {platform.python_build()}")
        
        # æ“ä½œç³»ç»Ÿä¿¡æ¯
        print("\nOperating System Information")
        print(f"OS: {platform.system()}")
        print(f"OS Release: {platform.release()}")
        print(f"OS Version: {platform.version()}")
        print(f"Machine: {platform.machine()}")
        print(f"Processor: {platform.processor()}")
        
        # å·²å®‰è£…çš„åŒ…åŠå…¶ç‰ˆæœ¬
        print("\nInstalled Packages")
        print("------------------")
        installed_packages = sorted(
            [(dist.key, dist.version) for dist in pkg_resources.working_set],
            key=lambda x: x[0].lower()
        )
        for package, version in installed_packages:
            print(f"{package}: {version}")
    
    # è°ƒç”¨å‡½æ•°
    session_info()
```
